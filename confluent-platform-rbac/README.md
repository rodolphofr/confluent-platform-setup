# RBAC (Role-Based Access Control)

Role-Based Access Control (RBAC) is a method of access control based on roles assigned to users within an organization. RBAC is defined through predefined roles and their associated privileges. Roles are a set of permissions that can be bound to a specific resource or service, allowing the associated privileges to be applied to that resource.

Using RBAC, you can manage who has access to specific Confluent Platform resources and what actions users can perform within those resources.

Confluent provides a set of [predefined roles](https://docs.confluent.io/platform/current/security/authorization/rbac/rbac-predefined-roles.html) for access control over resources such as organizations, environments, clusters, and Kafka-specific resources. Each role grants a specific set of permissions aligned with different responsibilities within the platform.

## Provisioning the Local Environment with RBAC

The `confluent-platform-rbac` environment is a Docker-based setup with all services running on a single host, intended exclusively for testing and demonstrating RBAC in the Confluent Platform.

## Prerequisites

This environment has been provisioned with:

* Docker version 27.5.1  
* Docker Compose version 2.32.4  
* OpenSSL version 3.0.2  
* Confluent Platform version 7.9.0  
* Kafka CLI version 2.13-4.0.0 for event production and consumption  
* curl version 7.81.0  

## Broker

The broker uses different listeners to manage internal and external communication. Below is a table of the configured listeners, their security protocols, usage descriptions, purposes, and corresponding ports.

| Listener Name | Security Protocol | Access & Usage Description | Purpose | Port |
|---------------|-------------------|-----------------------------|---------|------|
| PLAINTEXT     | PLAINTEXT         | Internal communication between brokers and Kafka components | Internal communication | 29092 |
| CONTROLLER    | PLAINTEXT         | Internal cluster control communication | Cluster control | 29093 |
| TOKEN         | SASL_PLAINTEXT    | Authentication and authorization for internal Confluent services and users | Internal communication | 9092 |
| EXTERNAL      | SASL_PLAINTEXT    | External access for authenticated producers and consumers | Secure external access | 9094 |
| JMX           | PLAINTEXT         | Monitoring and management via JMX | Monitoring | 9101 |
| MDS           | PLAINTEXT         | Metadata Service for managing permissions and authentication | Permissions management | 8090 |

## Importance of Public and Private .pem Keys

The public and private `.pem` keys are essential for the secure functioning of the Metadata Service (MDS) and the services that consume it. These keys are used to sign and verify authentication tokens, ensuring that only authorized users and services can access and interact with the Kafka cluster.

- **Private Key ([`private-key.pem`](security/private-key.pem))**: Used by MDS to sign authentication tokens.
- **Public Key ([`public-key.pem`](security/public-key.pem))**: Used by consuming services (such as brokers and Control Center) to verify the token signatures generated by MDS. This key can be distributed to enable token verification.

The use of these keys ensures the integrity and authentication of the tokens, allowing RBAC to function properly and securely.

> Note: This configuration is required for RBAC to be enabled and work correctly.

## Configuration

This environment has been validated with Docker as described in [Prerequisites](#prerequisites), using 12 cores and 8GB of memory.

## Start

The [`start.sh`](start.sh) script creates a basic Confluent Platform deployment with **RBAC**. It starts the Docker containers, assigns predefined roles to the appropriate users ([`login.properties`](./security/login.properties)), and sets up an environment ready for event production and consumption using a sample topic named `orders`. Follow the tutorial to understand how Kafka and the Confluent Platform work with RBAC.

1. To provision the environment, run the following command. On the first run, it will download all required Docker images and configure the environment.

```sh
./start.sh
```

As mentioned, this will download the images and apply the necessary configurations to run the Confluent Platform.

2. After the script finishes, check if the environment started successfully with the command below. Verify the container statuses under the `State` column:

```sh
docker compose ps
```

You should see output similar to:

```sh
NAME             IMAGE                                             COMMAND                  SERVICE          CREATED              STATUS                        PORTS
broker           confluentinc/cp-server:7.9.0                      "/etc/confluent/dock…"   broker           About a minute ago   Up About a minute (healthy)   0.0.0.0:8090->8090/tcp, :::8090->8090/tcp, 0.0.0.0:9094->9094/tcp, :::9094->9094/tcp, 0.0.0.0:9101->9101/tcp, :::9101->9101/tcp, 0.0.0.0:29092->29092/tcp, :::29092->29092/tcp, 9092/tcp
confluent-cli    confluentinc/confluent-cli:4.20.0                 "/bin/bash"              confluent-cli    About a minute ago   Up 46 seconds                 
control-center   confluentinc/cp-enterprise-control-center:7.9.0   "/etc/confluent/dock…"   control-center   39 seconds ago       Up 38 seconds                 0.0.0.0:9021->9021/tcp, :::9021->9021/tcp
```

All containers should have a status of `Up`.

## Confluent Control Center

The startup script sets up and grants admin (`SystemAdmin`) privileges to two users: `superUser` and `controlcenter`. These users have full control over the platform's features and the cluster. With these two accounts, you can perform advanced configurations.

1. Open your browser and go to the Confluent Control Center at: http://localhost:9021  
2. On the login screen, log in with `superUser` and password `superUser`, which has superuser access to the cluster. You can also log in with [other users](./security/login.properties) to see how the UI changes depending on their permissions.

## Authorization with RBAC

RBAC is powered by the [Metadata Service (MDS)](https://docs.confluent.io/platform/current/kafka/configure-mds/index.html#), which uses the Confluent Server Authorizer. You can see the security configuration for each component in the [`docker-compose`](./docker-compose.yml) file.

1. In the Confluent Control Center UI, go to the `Administration` menu and click `Manage role assignments`.
2. Click `Assignments` and then the Kafka cluster ID.
3. In the `Topic` list, check that some [users](./security/login.properties) have access to the sample topic group `orders`. This association was created during startup via the [`create-role-bindings.sh`](./scripts/create-role-bindings.sh) script.

Refer to the documentation for more on how to create and assign roles to users:

* [Manage RBAC roles with Control Center on Confluent Platform](https://docs.confluent.io/platform/current/control-center/security/c3-rbac-manage-roles-ui.html)
* [Use Predefined RBAC Roles in Confluent Platform](https://docs.confluent.io/platform/current/security/authorization/rbac/rbac-predefined-roles.html)
* [RBAC CLI Quickstart](https://docs.confluent.io/platform/current/security/authorization/rbac/rbac-cli-quickstart.html)

## Producing Events

To produce events to a Confluent Kafka topic, an external user must authenticate with the cluster and have the necessary RBAC permissions — specifically, the [`DeveloperWrite`](https://docs.confluent.io/platform/current/security/authorization/rbac/rbac-predefined-roles.html) role.

### RBAC-authorized user (e.g., user harry)

1. Make sure the user `harry` is configured in [`login.properties`](./security/login.properties) and has the necessary permissions to produce to the `orders` topic.

2. Ensure the user `harry` is configured in the `jaas.config` via the environment variable `KAFKA_LISTENER_NAME_EXTERNAL_PLAIN_SASL_JAAS_CONFIG` in the [docker-compose](docker-compose.yml).

3. Produce events to the `orders` topic:

```sh
bin/kafka-console-producer.sh --broker-list localhost:9094 \
  --topic orders \
  --producer-property security.protocol=SASL_PLAINTEXT \
  --producer-property sasl.mechanism=PLAIN \
  --producer-property sasl.jaas.config='org.apache.kafka.common.security.plain.PlainLoginModule required username="harry" password="harry";'
```

## Consuming Events

To consume events from a Confluent Kafka topic, an external user must authenticate with the cluster and have the necessary RBAC permissions — specifically, the [`DeveloperRead`](https://docs.confluent.io/platform/current/security/authorization/rbac/rbac-predefined-roles.html) role and be part of a group with read privileges. In this case, `console-consumer` was configured in the [`create-role-bindings`](./scripts/create-role-bindings.sh) script during environment provisioning.

### RBAC-authorized user (e.g., user harry)

1. Ensure that user `harry` is configured in [`login.properties`](./security/login.properties) and has the necessary permissions to consume from the `orders` topic.

2. Ensure the user `harry` is configured in `jaas.config` via the `KAFKA_LISTENER_NAME_EXTERNAL_PLAIN_SASL_JAAS_CONFIG` environment variable in the [docker-compose](docker-compose.yml).

3. Consume events from the `orders` topic:

```sh
bin/kafka-console-consumer.sh --bootstrap-server localhost:9094 \
  --topic orders \
  --group console-consumer \
  --consumer-property security.protocol=SASL_PLAINTEXT \
  --consumer-property sasl.mechanism=PLAIN \
  --consumer-property sasl.jaas.config='org.apache.kafka.common.security.plain.PlainLoginModule required username="harry" password="harry";'
```

## Stopping the Environment

To stop the provisioned environment and clean up any generated data and files, run:

```sh
docker compose down --volumes
```